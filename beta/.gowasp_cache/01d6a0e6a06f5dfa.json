{
  "stage": "deep_dive",
  "file": "smart__.py",
  "prompt": "You are a Principal Application Security Engineer. Your analysis must be meticulous, pragmatic, and map to industry standards. Analyze the following code in the context of the user's question.\n\nFILE: smart__.py\nQUESTION: lets analyze and optomize this team\n\nProvide your analysis in this exact JSON format. Your entire response must be ONLY the JSON object.\n{\n  \"relevance\": \"HIGH|MEDIUM|LOW|NONE\",\n  \"insights\": [\n    {\n      \"finding\": \"A concise description of the specific security weakness.\",\n      \"impact\": \"CRITICAL|HIGH|MEDIUM|LOW\",\n      \"confidence\": \"HIGH|MEDIUM|LOW\",\n      \"effort\": \"HIGH|MEDIUM|LOW\",\n      \"line_number\": 45,\n      \"cwe\": \"CWE-ID (e.g., 'CWE-89' for SQL Injection). If not applicable or unsure, use 'N/A'.\",\n      \"recommendation\": \"A specific, actionable recommendation with a brief 'why'.\"\n    }\n  ]\n}\n\nCODE TO ANALYZE:\n#!/usr/bin/env python3\n\"\"\"\nSmart Code Analyzer (full features + caching)\n\nStages:\n  1. Prioritization\n  2. Deep Dive\n  3. Synthesis\n  4. (Optional) Annotation & Payload Generation\n  5. (Optional with --optimize) Code Quality Improvement\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nimport hashlib\nimport html\nimport json\nimport os\nimport re\nimport sys\nimport time\nfrom dataclasses import dataclass, asdict\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Any, Dict, Final, List, Optional, Sequence\n\nimport anthropic\nfrom rich.console import Console\nfrom rich.markdown import Markdown\nfrom rich.panel import Panel\nfrom rich.syntax import Syntax\nfrom rich.table import Table\n\nfrom prompts import PromptFactory\n\n\n# ---------- Constants ----------\nCLAUDE_MODEL: Final = \"claude-3-5-haiku-20241022\"\nDEFAULT_MAX_FILE_BYTES: Final = 500_000\nDEFAULT_MAX_FILES: Final = 400\nSKIP_DIRS: Final = {\".git\", \"node_modules\", \"__pycache__\", \"vendor\", \"build\", \"dist\"}\nCODE_EXTS: Final = {\".py\", \".go\", \".java\", \".js\", \".ts\", \".php\", \".rb\", \".jsx\", \".tsx\"}\nYAML_EXTS: Final = {\".yaml\", \".yml\"}\nHELM_EXTS: Final = {\".tpl\", \".gotmpl\"}\n\n\n# ---------- Data structures ----------\n@dataclass\nclass ConversationLog:\n    stage: str\n    file: Optional[str]\n    prompt: str\n    raw_response: str\n    parsed: Optional[dict]\n    timestamp: str\n\n\n@dataclass(slots=True)\nclass Finding:\n    file_path: str\n    finding: str\n    recommendation: str\n    relevance: str\n    impact: str\n    confidence: str\n    effort: str\n    cwe: str\n    line_number: Optional[int] = None\n    annotated_snippet: Optional[str] = None\n\n    @classmethod\n    def from_dict(cls, d: dict, file_path: str, relevance: str) -> Finding:\n        return cls(\n            file_path=file_path,\n            relevance=relevance,\n            finding=str(d.get(\"finding\", \"N/A\")),\n            recommendation=str(d.get(\"recommendation\", \"N/A\")),\n            impact=str(d.get(\"impact\", \"N/A\")),\n            confidence=str(d.get(\"confidence\", \"N/A\")),\n            effort=str(d.get(\"effort\", \"N/A\")),\n            cwe=str(d.get(\"cwe\", \"N/A\")),\n            line_number=d.get(\"line_number\"),\n        )\n\n\n@dataclass(slots=True)\nclass AnalysisReport:\n    repo_path: str\n    question: str\n    timestamp: str\n    file_count: int\n    insights: List[Finding]\n    synthesis: str\n\n\n# ---------- Cache Manager ----------\nclass CacheManager:\n    def __init__(self, cache_dir: str, use_cache: bool = True):\n        self.cache_dir = Path(cache_dir)\n        self.cache_dir.mkdir(parents=True, exist_ok=True)\n        self.use_cache = use_cache\n        self.session_logs: List[ConversationLog] = []\n\n    def _hash_key(self, stage: str, file: Optional[str], prompt: str) -> str:\n        h = hashlib.sha256()\n        h.update(f\"{stage}|{file or ''}|{prompt}\".encode(\"utf-8\"))\n        return h.hexdigest()[:16]\n\n    def get(self, stage: str, file: Optional[str], prompt: str) -> Optional[ConversationLog]:\n        if not self.use_cache:\n            return None\n        key = self._hash_key(stage, file, prompt)\n        path = self.cache_dir / f\"{key}.json\"\n        if path.exists():\n            try:\n                data = json.loads(path.read_text(encoding=\"utf-8\"))\n                return ConversationLog(**data)\n            except Exception:\n                return None\n        return None\n\n    def save(\n        self, stage: str, file: Optional[str], prompt: str, raw: str, parsed: Optional[dict]\n    ) -> ConversationLog:\n        entry = ConversationLog(\n            stage=stage,\n            file=file,\n            prompt=prompt,\n            raw_response=raw,\n            parsed=parsed,\n            timestamp=datetime.now(timezone.utc).isoformat(),\n        )\n        key = self._hash_key(stage, file, prompt)\n        path = self.cache_dir / f\"{key}.json\"\n        path.write_text(json.dumps(asdict(entry), indent=2), encoding=\"utf-8\")\n        self.session_logs.append(entry)\n        return entry\n\n    def save_session_log(self) -> None:\n        if not self.session_logs:\n            return\n        session_file = (\n            self.cache_dir / f\"session_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.json\"\n        )\n        data = [asdict(log) for log in self.session_logs]\n        session_file.write_text(json.dumps(data, indent=2), encoding=\"utf-8\")\n\n\n# ---------- Helpers ----------\ndef get_api_key() -> str:\n    api_key = os.getenv(\"CLAUDE_API_KEY\")\n    if not api_key:\n        print(\"Error: CLAUDE_API_KEY not set.\", file=sys.stderr)\n        sys.exit(1)\n    return api_key\n\n\n_CODE_FENCE_RE = re.compile(r\"^```(?:json)?\\s*|\\s*```$\", re.MULTILINE)\n\n\ndef parse_json_response(response_text: str) -> Optional[dict]:\n    if not response_text:\n        return None\n    cleaned = _CODE_FENCE_RE.sub(\"\", response_text).strip()\n    start, end = cleaned.find(\"{\"), cleaned.rfind(\"}\")\n    if start != -1 and end != -1 and end > start:\n        try:\n            return json.loads(cleaned[start : end + 1])\n        except json.JSONDecodeError:\n            return None\n    return None\n\n\ndef scan_repo_files(\n    repo_path: str,\n    include_yaml: bool,\n    include_helm: bool,\n    max_file_bytes: int,\n    max_files: int,\n) -> List[Path]:\n    repo = Path(repo_path)\n    if not repo.is_dir():\n        raise ValueError(f\"Repository path '{repo_path}' is not a directory\")\n    allowed_exts = set(CODE_EXTS)\n    if include_yaml:\n        allowed_exts |= YAML_EXTS\n    if include_helm:\n        allowed_exts |= HELM_EXTS\n    results: List[Path] = []\n    for file_path in repo.rglob(\"*\"):\n        if len(results) >= max_files:\n            break\n        if not file_path.is_file():\n            continue\n        if any(skip in file_path.parts for skip in SKIP_DIRS):\n            continue\n        if file_path.suffix.lower() not in allowed_exts:\n            continue\n        try:\n            if file_path.stat().st_size > max_file_bytes:\n                continue\n        except OSError:\n            continue\n        results.append(file_path)\n    return sorted(results, key=lambda p: (p.suffix, p.name.lower()))\n\n\n# ---------- Core Analyzer ----------\nclass SmartAnalyzer:\n    def __init__(self, console: Console, client: anthropic.Anthropic, cache: CacheManager):\n        self.console = console\n        self.client = client\n        self.cache = cache\n\n    def _call_claude(\n        self, stage: str, file: Optional[str], prompt: str, max_tokens: int = 4000\n    ) -> Optional[str]:\n        cached = self.cache.get(stage, file, prompt)\n        if cached:\n            self.console.print(f\"[dim]Cache hit for {stage} ({file or 'n/a'})[/dim]\")\n            return cached.raw_response\n        try:\n            response = self.client.messages.create(\n                model=CLAUDE_MODEL,\n                max_tokens=max_tokens,\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            raw = response.content[0].text if response.content else \"\"\n            parsed = parse_json_response(raw)\n            self.cache.save(stage, file, prompt, raw, parsed)\n            return raw\n        except Exception as e:\n            self.console.print(f\"[red]API Error: {e}[/red]\")\n            return None\n\n    def run_prioritization_stage(\n        self, all_files: List[Path], question: str, debug: bool, limit: int\n    ) -> Optional[List[Dict[str, str]]]:\n        self.console.print(\"[bold]Stage 1: Prioritization[/bold]\")\n        if not all_files:\n            return None\n        prompt = PromptFactory.prioritization(all_files, question, limit)\n        raw = self._call_claude(\"prioritization\", None, prompt)\n        if not raw:\n            return None\n        if debug:\n            self.console.print(Panel(raw, title=\"RAW API RESPONSE (Prioritization)\"))\n        parsed = parse_json_response(raw)\n        if parsed and isinstance(parsed.get(\"prioritized_files\"), list):\n            prioritized_info = parsed[\"prioritized_files\"]\n            self.console.print(\n                f\"[green]\u2713 AI has suggested {len(prioritized_info)} files for analysis.[/green]\\n\"\n            )\n            return prioritized_info\n        self.console.print(\n            \"[yellow]Could not parse prioritization response. Continuing with all files.[/yellow]\"\n        )\n        return None\n\n    def run_deep_dive_stage(\n        self,\n        files: List[Path],\n        question: str,\n        verbose: bool,\n        debug: bool,\n        threshold: Optional[str],\n    ) -> List[Finding]:\n        self.console.print(\"\\n[bold]Stage 2: Deep Dive[/bold]\")\n        findings: List[Finding] = []\n        for i, file_path in enumerate(files, 1):\n            self.console.print(f\"[[bold]{i}/{len(files)}[/bold]] Analyzing {file_path.name}...\")\n            try:\n                content = file_path.read_text(encoding=\"utf-8\", errors=\"replace\")\n                lines = content.splitlines()\n            except OSError as e:\n                self.console.print(f\"  [red]Error reading {file_path}: {e}[/red]\")\n                continue\n\n            if file_path.suffix.lower() in YAML_EXTS:\n                prompt = PromptFactory.deep_dive_yaml(file_path, content, question)\n            elif file_path.suffix.lower() in HELM_EXTS or \"templates\" in file_path.parts:\n                prompt = PromptFactory.deep_dive_helm(file_path, content, question)\n            else:\n                prompt = PromptFactory.deep_dive(file_path, content, question)\n\n            raw = self._call_claude(\"deep_dive\", str(file_path), prompt)\n            if not raw:\n                continue\n            if debug:\n                self.console.print(Panel(raw, title=f\"RAW API RESPONSE ({file_path.name})\"))\n\n            parsed = parse_json_response(raw)\n            if parsed and isinstance(parsed.get(\"insights\"), list):\n                relevance = str(parsed.get(\"relevance\", \"N/A\"))\n                if threshold and relevance not in (\"HIGH\", threshold):\n                    continue\n\n                file_insights: Sequence[dict] = parsed[\"insights\"]\n                self.console.print(f\"   Relevance: {relevance}, Found: {len(file_insights)} insights\")\n                for ins in file_insights:\n                    findings.append(Finding.from_dict(ins, str(file_path), relevance))\n\n                    if verbose:\n                        line_num_val = ins.get(\"line_number\")\n                        code_line_printed = False\n                        try:\n                            # Attempt to parse line number, forgiving str/int mismatch from AI\n                            if line_num_val is not None:\n                                line_num_int = int(line_num_val)\n                                if 0 < line_num_int <= len(lines):\n                                    code_line = lines[line_num_int - 1]\n\n                                    # Only print the code line if it contains non-whitespace chars\n                                    if code_line.strip():\n                                        lexer = \"java\" if file_path.suffix == \".java\" else \"python\"\n                                        self.console.print(\n                                            Syntax(\n                                                code_line,\n                                                lexer,\n                                                theme=\"monokai\",\n                                                line_numbers=True,\n                                                start_line=line_num_int,\n                                            )\n                                        )\n                                    else:\n                                        self.console.print(\n                                            f\"[dim]   (Line {line_num_int} is empty)[/dim]\"\n                                        )\n                                    code_line_printed = True\n                        except (ValueError, TypeError):\n                            # Fail gracefully if line number is not a valid int\n                            pass\n\n                        finding_text = f\"     Finding: {ins.get('finding')} (Impact: {ins.get('impact')}, CWE: {ins.get('cwe')})\"\n                        # Adjust indentation if no code line was printed\n                        if not code_line_printed:\n                            finding_text = finding_text.lstrip()\n\n                        self.console.print(finding_text)\n                        self.console.print(\"\")  # Add vertical space for readability\n            time.sleep(1)\n        self.console.print(f\"\\n[green]\u2713 Deep dive complete. Found {len(findings)} total insights.[/green]\")\n        return findings\n\n    def run_synthesis_stage(self, findings: List[Finding], question: str) -> str:\n        self.console.print(\"\\n[bold]Stage 3: Synthesis[/bold]\")\n        if not findings:\n            return \"No insights were found to synthesize.\"\n        prompt = PromptFactory.synthesis(findings, question)\n        raw = self._call_claude(\"synthesis\", None, prompt)\n        self.console.print(\"[green]\u2713 Synthesis complete.[/green]\\n\")\n        return raw or \"Synthesis failed.\"\n\n    def run_annotation_stage(self, top_findings: List[Finding], debug: bool) -> None:\n        self.console.print(\"\\n[bold]Stage: Code Annotation[/bold]\")\n        for finding in top_findings:\n            try:\n                content = Path(finding.file_path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n                prompt = PromptFactory.annotation(finding, content)\n                raw = self._call_claude(\"annotation\", finding.file_path, prompt)\n                if not raw:\n                    continue\n                if debug:\n                    self.console.print(\n                        Panel(\n                            raw, title=f\"RAW API RESPONSE (Annotation for {Path(finding.file_path).name})\"\n                        )\n                    )\n\n                parsed = parse_json_response(raw)\n                if parsed and \"annotated_snippet\" in parsed:\n                    finding.annotated_snippet = parsed[\"annotated_snippet\"]\n                    self.console.print(f\"\u2713 Annotated snippet for [yellow]'{finding.finding}'[/yellow]\")\n                time.sleep(1)\n            except Exception as e:\n                self.console.print(f\"[red]Error annotating {finding.file_path}: {e}[/red]\")\n\n    def run_payload_generation_stage(self, top_findings: List[Finding], debug: bool) -> None:\n        self.console.print(\"\\n[bold]Stage 4: Payload Generation[/bold]\")\n        for f in top_findings:\n            try:\n                snippet = Path(f.file_path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n            except Exception:\n                snippet = \"Could not read snippet.\"\n            prompt = PromptFactory.payload_generation(f, snippet[:500])\n            raw = self._call_claude(\"payload\", f.file_path, prompt)\n            if not raw:\n                continue\n            if debug:\n                self.console.print(\n                    Panel(raw, title=f\"RAW API RESPONSE (Payloads for {Path(f.file_path).name})\")\n                )\n            parsed = parse_json_response(raw)\n            if parsed:\n                rt, bt = parsed.get(\"red_team_payload\", {}), parsed.get(\"blue_team_payload\", {})\n                self.console.print(\n                    Panel(\n                        f\"[bold red]Red Team[/bold red]\\nPayload: `{rt.get('payload','')}`\\n{rt.get('explanation','')}\\n\\n\"\n                        f\"[bold green]Blue Team[/bold green]\\nPayload: `{bt.get('payload','')}`\\n{bt.get('explanation','')}\",\n                        title=f\"Payloads for '{f.finding}'\",\n                        border_style=\"magenta\",\n                    )\n                )\n            time.sleep(1)\n\n    def run_code_improvement_stage(\n        self, files: List[Path], focus_areas: List[str], debug: bool\n    ) -> Dict[str, List[dict]]:\n        \"\"\"Analyze Python files for code quality improvements (ONLY when --optimize flag is used).\"\"\"\n        self.console.print(\"\\n[bold cyan]Stage: Code Quality Optimization[/bold cyan]\")\n        improvements_by_file: Dict[str, List[dict]] = {}\n        \n        python_files = [f for f in files if f.suffix == \".py\"]\n        if not python_files:\n            self.console.print(\"[yellow]No Python files found to optimize.[/yellow]\")\n            return improvements_by_file\n        \n        for i, file_path in enumerate(python_files, 1):\n            self.console.print(\n                f\"[[bold]{i}/{len(python_files)}[/bold]] Optimizing {file_path.name}...\"\n            )\n            try:\n                content = file_path.read_text(encoding=\"utf-8\", errors=\"replace\")\n            except OSError as e:\n                self.console.print(f\"  [red]Error reading {file_path}: {e}[/red]\")\n                continue\n            \n            prompt = PromptFactory.code_improvement(\n                file_path, content, focus_areas\n            )\n            raw = self._call_claude(\n                \"code_improvement\", str(file_path), prompt, max_tokens=6000\n            )\n            \n            if not raw:\n                continue\n                \n            if debug:\n                self.console.print(\n                    Panel(raw, title=f\"RAW API RESPONSE ({file_path.name})\")\n                )\n            \n            parsed = parse_json_response(raw)\n            if parsed and isinstance(parsed.get(\"improvements\"), list):\n                quality = parsed.get(\"overall_quality\", \"N/A\")\n                improvements = parsed[\"improvements\"]\n                improvements_by_file[str(file_path)] = improvements\n                \n                self.console.print(\n                    f\"   Quality: [{'green' if quality == 'EXCELLENT' else 'yellow'}]{quality}[/], \"\n                    f\"Improvements: {len(improvements)}\"\n                )\n                \n                # Display high-impact improvements\n                high_impact = [\n                    imp for imp in improvements if imp.get(\"impact\") == \"HIGH\"\n                ]\n                if high_impact:\n                    self.console.print(\n                        f\"   [bold red]\u26a0 {len(high_impact)} HIGH impact \"\n                        f\"improvement(s) found[/bold red]\"\n                    )\n            \n            time.sleep(1)\n        \n        self.console.print(\n            f\"\\n[green]\u2713 Code optimization complete. \"\n            f\"Analyzed {len(python_files)} Python files.[/green]\"\n        )\n        return improvements_by_file\n\n\n# ---------- Output ----------\nclass OutputManager:\n    def __init__(self, console: Console):\n        self.console = console\n\n    def display_console_summary(self, report: AnalysisReport) -> None:\n        self.console.print(\n            Panel(\n                Markdown(report.synthesis),\n                title=\"[bold blue]Analysis Report & Strategic Plan[/bold blue]\",\n                border_style=\"blue\",\n                expand=False,\n            )\n        )\n\n        annotated_findings = [f for f in report.insights if f.annotated_snippet]\n        if annotated_findings:\n            self.console.print(\"\\n[bold magenta]Annotated Code Snippets[/bold magenta]\")\n            for finding in annotated_findings:\n                lexer_name = \"java\" if \".java\" in finding.file_path else \"python\"\n                syntax = Syntax(\n                    finding.annotated_snippet, lexer_name, theme=\"monokai\", line_numbers=True\n                )\n                panel_title = f\"[cyan]{Path(finding.file_path).name}[/cyan] - [yellow]{finding.finding}[/yellow] ({finding.cwe})\"\n                self.console.print(Panel(syntax, title=panel_title, border_style=\"magenta\"))\n\n    def display_code_improvements(\n        self, improvements_by_file: Dict[str, List[dict]]\n    ) -> None:\n        \"\"\"Display code improvement suggestions in a readable format.\"\"\"\n        if not improvements_by_file:\n            return\n        \n        self.console.print(\n            \"\\n[bold cyan]\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501[/bold cyan]\"\n        )\n        self.console.print(\n            \"[bold cyan]Code Quality Optimization Results[/bold cyan]\"\n        )\n        self.console.print(\n            \"[bold cyan]\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501[/bold cyan]\\n\"\n        )\n        \n        for file_path, improvements in improvements_by_file.items():\n            if not improvements:\n                continue\n            \n            file_name = Path(file_path).name\n            self.console.print(f\"\\n[cyan]\u2501\u2501\u2501 {file_name} \u2501\u2501\u2501[/cyan]\")\n            \n            for imp in improvements:\n                category = imp.get(\"category\", \"general\")\n                line = imp.get(\"line_number\", \"?\")\n                impact = imp.get(\"impact\", \"?\")\n                \n                # Color based on category\n                color_map = {\n                    \"security\": \"red\",\n                    \"performance\": \"yellow\",\n                    \"typing\": \"blue\",\n                    \"readability\": \"green\",\n                    \"pythonic\": \"magenta\"\n                }\n                color = color_map.get(category, \"white\")\n                \n                self.console.print(\n                    f\"\\n[{color}]\u25cf {category.upper()}[/{color}] \"\n                    f\"(Line {line}, Impact: {impact})\"\n                )\n                self.console.print(f\"  [dim]{imp.get('explanation', '')}[/dim]\")\n                \n                # Show before/after if available\n                if imp.get(\"current_code\"):\n                    self.console.print(\"\\n  [red]Before:[/red]\")\n                    self.console.print(\n                        Syntax(\n                            imp[\"current_code\"],\n                            \"python\",\n                            theme=\"monokai\",\n                            line_numbers=False,\n                            indent_guides=False\n                        )\n                    )\n                \n                if imp.get(\"improved_code\"):\n                    self.console.print(\"  [green]After:[/green]\")\n                    self.console.print(\n                        Syntax(\n                            imp[\"improved_code\"],\n                            \"python\",\n                            theme=\"monokai\",\n                            line_numbers=False,\n                            indent_guides=False\n                        )\n                    )\n\n    def save_reports(\n        self, report: AnalysisReport, formats: List[str], output_base: Optional[str]\n    ) -> None:\n        base = Path(\n            output_base\n            or f\"analysis_{Path(report.repo_path).name}_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}\"\n        )\n        for fmt in formats:\n            if fmt == \"console\":\n                continue\n            out = base.with_suffix(f\".{fmt}\")\n            try:\n                if fmt == \"markdown\":\n                    content = f\"# Analysis for `{report.repo_path}`\\n\\n## Question: {report.question}\\n\\n---\\n\\n{report.synthesis}\"\n                elif fmt == \"html\":\n                    md_html = Markdown(report.synthesis)._render_str(self.console)\n                    content = f\"<!doctype html><html><head><meta charset='utf-8'><title>Analysis Report</title><style>body{{font-family:sans-serif;max-width:800px;margin:2em auto;}}pre{{background:#f4f4f4;padding:1em;}}</style></head><body><h1>Analysis for <code>{report.repo_path}</code></h1><h2>Question: {report.question}</h2><hr/>{md_html}</body></html>\"\n                elif fmt == \"json\":\n                    content = json.dumps([asdict(f) for f in report.insights], indent=2)\n                else:\n                    content = \"\"\n                out.write_text(content, encoding=\"utf-8\")\n                self.console.print(f\"[green]\u2713 Saved report to {out}[/green]\")\n            except Exception as e:\n                self.console.print(f\"[red]Error saving {fmt} report: {e}[/red]\")\n\n    def save_improvement_report(\n        self, improvements: Dict[str, List[dict]], output_path: Path\n    ) -> None:\n        \"\"\"Save code improvements to a structured markdown file.\"\"\"\n        if not improvements:\n            return\n        \n        try:\n            # Markdown format\n            content = [\"# Code Quality Optimization Report\\n\"]\n            content.append(\n                f\"Generated: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}\\n\\n\"\n            )\n            \n            for file_path, imps in improvements.items():\n                file_name = Path(file_path).name\n                content.append(f\"\\n## {file_name}\\n\")\n                for imp in imps:\n                    content.append(\n                        f\"### Line {imp.get('line_number', '?')}: \"\n                        f\"{imp.get('category', 'general').title()}\\n\"\n                    )\n                    content.append(f\"**Impact**: {imp.get('impact', 'N/A')}\\n\\n\")\n                    content.append(f\"{imp.get('explanation', '')}\\n\\n\")\n                    if imp.get(\"improved_code\"):\n                        content.append(\"```python\\n\")\n                        content.append(imp[\"improved_code\"])\n                        content.append(\"\\n```\\n\\n\")\n            \n            output_path.write_text(\"\".join(content), encoding=\"utf-8\")\n            self.console.print(\n                f\"[green]\u2713 Saved optimization report to {output_path}[/green]\"\n            )\n        except Exception as e:\n            self.console.print(f\"[red]Error saving optimization report: {e}[/red]\")\n\n\n# ---------- Interactivity ----------\ndef clarify_question_interactively(question: str, console: Console) -> str:\n    if \"security\" in question.lower():\n        console.print(\n            \"\\n[bold cyan]?[/] Your question is about [bold]security[/bold]. To focus the analysis, what aspect are you most interested in?\"\n        )\n        options = [\n            \"Injection Vulnerabilities (SQLi, XSS)\",\n            \"Authentication & Authorization\",\n            \"Insecure Data Handling (Secrets, PII)\",\n            \"Dependency & Configuration Issues\",\n        ]\n        for i, opt in enumerate(options, 1):\n            console.print(f\"  ({i}) {opt}\")\n        choice = input(\"Enter number (or press Enter to skip): \").strip()\n        if choice.isdigit() and 1 <= int(choice) <= len(options):\n            clarification = options[int(choice) - 1]\n            console.print(f\"[dim]Focusing on: {clarification}[/dim]\")\n            return f\"{question}, focusing specifically on {clarification}.\"\n    return question\n\n\n# ---------- CLI & Main ----------\ndef create_parser() -> argparse.ArgumentParser:\n    p = argparse.ArgumentParser(description=\"Smart Code Analyzer with caching + full features\")\n    p.add_argument(\"repo_path\", help=\"Path to the repository to analyze\")\n    p.add_argument(\"question\", nargs=\"?\", help=\"Analysis question\")\n    p.add_argument(\"--cache-dir\", default=\".gowasp_cache\", help=\"Directory for conversation cache\")\n    p.add_argument(\"--no-cache\", action=\"store_true\", help=\"Disable cache (always hit API)\")\n    p.add_argument(\n        \"--save-conversations\", action=\"store_true\", help=\"Save full session log as JSON\"\n    )\n    p.add_argument(\"--include-yaml\", action=\"store_true\", help=\"Include .yaml/.yml files\")\n    p.add_argument(\"--include-helm\", action=\"store_true\", help=\"Include Helm templates\")\n    p.add_argument(\"--max-file-bytes\", type=int, default=DEFAULT_MAX_FILE_BYTES)\n    p.add_argument(\"--max-files\", type=int, default=DEFAULT_MAX_FILES)\n    p.add_argument(\"--prioritize-top\", type=int, default=15, help=\"Ask AI to prioritize top N files.\")\n    p.add_argument(\n        \"--format\",\n        nargs=\"*\",\n        default=[\"console\"],\n        choices=[\"console\", \"html\", \"markdown\", \"json\"],\n    )\n    p.add_argument(\"--output\", \"-o\", help=\"Base output filename\")\n    p.add_argument(\n        \"--top-n\", type=int, default=5, help=\"Number of items for payload/annotation generation\"\n    )\n    p.add_argument(\n        \"--threshold\", choices=[\"HIGH\", \"MEDIUM\"], help=\"Filter findings below this relevance\"\n    )\n    p.add_argument(\"--generate-payloads\", action=\"store_true\", help=\"Generate Red/Blue payloads\")\n    p.add_argument(\n        \"--annotate-code\", action=\"store_true\", help=\"Generate annotated code snippets for top findings\"\n    )\n    p.add_argument(\n        \"-v\", \"--verbose\", action=\"store_true\", help=\"Print findings inline with code context\"\n    )\n    p.add_argument(\"--debug\", action=\"store_true\", help=\"Print raw API responses\")\n    \n    # NEW: Code optimization flags\n    p.add_argument(\n        \"--optimize\",\n        action=\"store_true\",\n        help=\"Run code quality optimization analysis on Python files\"\n    )\n    p.add_argument(\n        \"--focus\",\n        nargs=\"*\",\n        choices=[\"typing\", \"readability\", \"security\", \"performance\", \"pythonic\"],\n        help=\"Focus areas for code optimization (default: all). Only used with --optimize\"\n    )\n    \n    return p\n\n\ndef main() -> None:\n    args = create_parser().parse_args()\n    console = Console()\n\n    api_key = get_api_key()\n    client = anthropic.Anthropic(api_key=api_key)\n    cache = CacheManager(args.cache_dir, use_cache=not args.no_cache)\n    analyzer = SmartAnalyzer(console, client, cache)\n\n    repo_path = Path(args.repo_path)\n    if not repo_path.exists():\n        console.print(f\"[red]Error: Repository path '{repo_path}' does not exist[/red]\")\n        sys.exit(1)\n\n    question = args.question or input(\"Enter analysis question: \").strip()\n    if not question:\n        console.print(\"[red]No question provided[/red]\")\n        sys.exit(1)\n\n    question = clarify_question_interactively(question, console)\n\n    files = scan_repo_files(\n        repo_path, args.include_yaml, args.include_helm, args.max_file_bytes, args.max_files\n    )\n    console.print(f\"\\nFound [bold]{len(files)}[/bold] files to analyze.\")\n\n    prioritized_info = analyzer.run_prioritization_stage(\n        files, question, args.debug, args.prioritize_top\n    )\n\n    files_to_analyze = files\n    if prioritized_info:\n        table = Table(title=\"AI-Prioritized Files for Analysis\")\n        table.add_column(\"File Name\", style=\"cyan\")\n        table.add_column(\"Reason for Selection\", style=\"magenta\")\n        for item in prioritized_info:\n            table.add_row(item.get(\"file_name\", \"N/A\"), item.get(\"reason\", \"N/A\"))\n        console.print(table)\n\n        while True:\n            prompt = f\"[?] Proceed with all {len(prioritized_info)} files? ([Y]es / [N]o / Enter a number to analyze less): \"\n            choice = input(prompt).strip().lower()\n\n            if choice in (\"y\", \"yes\", \"\"):\n                break\n            elif choice in (\"n\", \"no\"):\n                console.print(\"[yellow]Analysis aborted by user.[/yellow]\")\n                sys.exit(0)\n            elif choice.isdigit():\n                num_to_analyze = int(choice)\n                if 0 < num_to_analyze <= len(prioritized_info):\n                    prioritized_info = prioritized_info[:num_to_analyze]\n                    console.print(f\"[dim]Proceeding with the top {num_to_analyze} file(s).[/dim]\")\n                    break\n                else:\n                    console.print(f\"[red]Please enter a number between 1 and {len(prioritized_info)}.[/red]\")\n            else:\n                console.print(\"[red]Invalid input. Please enter 'y', 'n', or a number.[/red]\")\n\n        prioritized_filenames = {item[\"file_name\"] for item in prioritized_info if \"file_name\" in item}\n        files_to_analyze = [p for p in files if p.name in prioritized_filenames]\n\n    findings = analyzer.run_deep_dive_stage(\n        files_to_analyze, question, args.verbose, args.debug, args.threshold\n    )\n\n    impact_order = {\"CRITICAL\": 4, \"HIGH\": 3, \"MEDIUM\": 2, \"LOW\": 1}\n    findings.sort(key=lambda f: impact_order.get(f.impact, 0), reverse=True)\n\n    synthesis = analyzer.run_synthesis_stage(findings, question)\n\n    report = AnalysisReport(\n        repo_path=str(repo_path),\n        question=question,\n        timestamp=datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\"),\n        file_count=len(files_to_analyze),\n        insights=findings,\n        synthesis=synthesis,\n    )\n\n    # Curate top findings for actions\n    top_findings_for_action = []\n    processed_files = set()\n    if findings:\n        for finding in findings:\n            if len(top_findings_for_action) >= args.top_n:\n                break\n            if finding.file_path not in processed_files:\n                top_findings_for_action.append(finding)\n                processed_files.add(finding.file_path)\n\n    if args.annotate_code and top_findings_for_action:\n        analyzer.run_annotation_stage(top_findings_for_action, args.debug)\n\n    out = OutputManager(console)\n    if \"console\" in args.format:\n        out.display_console_summary(report)\n\n    file_formats = [f for f in args.format if f != \"console\"]\n    if file_formats:\n        out.save_reports(report, file_formats, args.output)\n\n    if args.generate_payloads and top_findings_for_action:\n        analyzer.run_payload_generation_stage(top_findings_for_action, args.debug)\n\n    # NEW: Code optimization stage (ONLY runs if --optimize flag is set)\n    improvements = {}\n    if args.optimize:\n        focus_areas = args.focus or []\n        improvements = analyzer.run_code_improvement_stage(\n            files_to_analyze, focus_areas, args.debug\n        )\n        \n        # Display improvements in console\n        if improvements:\n            out.display_code_improvements(improvements)\n            \n            # Save improvements to file if requested\n            if args.output:\n                improvement_output = Path(args.output).with_suffix(\".optimization.md\")\n                out.save_improvement_report(improvements, improvement_output)\n\n    if args.save_conversations:\n        cache.save_session_log()\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "raw_response": "{\n  \"relevance\": \"HIGH\",\n  \"insights\": [\n    {\n      \"finding\": \"Complex, feature-rich code analyzer with multi-stage AI-driven analysis\",\n      \"impact\": \"MEDIUM\",\n      \"confidence\": \"HIGH\", \n      \"effort\": \"LOW\",\n      \"line_number\": null,\n      \"cwe\": \"N/A\",\n      \"recommendation\": \"The code demonstrates a robust, modular architecture with clear separation of concerns. Consider adding more comprehensive error handling and logging.\"\n    },\n    {\n      \"finding\": \"Potential over-reliance on external AI service for code analysis\",\n      \"impact\": \"MEDIUM\", \n      \"confidence\": \"MEDIUM\",\n      \"effort\": \"MEDIUM\", \n      \"line_number\": 229,\n      \"cwe\": \"CWE-754\",\n      \"recommendation\": \"Implement fallback mechanisms and local analysis capabilities to reduce dependency on external AI services. Add circuit breaker patterns for API calls.\"\n    },\n    {\n      \"finding\": \"Large, monolithic script with multiple responsibilities\",\n      \"impact\": \"LOW\",\n      \"confidence\": \"HIGH\",\n      \"effort\": \"HIGH\",\n      \"line_number\": null,\n      \"cwe\": \"N/A\", \n      \"recommendation\": \"Consider breaking down the script into smaller, more focused modules. Implement dependency injection and use more abstract interfaces for better testability.\"\n    },\n    {\n      \"finding\": \"Potential security risk in dynamic prompt generation and AI response parsing\",\n      \"impact\": \"HIGH\",\n      \"confidence\": \"MEDIUM\",\n      \"effort\": \"MEDIUM\",\n      \"line_number\": 348,\n      \"cwe\": \"CWE-94\",\n      \"recommendation\": \"Add more robust input sanitization and validation for prompts and AI responses. Implement stricter JSON parsing with schema validation.\"\n    },\n    {\n      \"finding\": \"Extensive use of environment variables and API key management\",\n      \"impact\": \"MEDIUM\",\n      \"confidence\": \"HIGH\",\n      \"effort\": \"LOW\",\n      \"line_number\": 269,\n      \"cwe\": \"CWE-522\",\n      \"recommendation\": \"Enhance API key retrieval with more secure methods like vault integration or secure secret management. Add logging and monitoring for API key access attempts.\"\n    }\n  ]\n}",
  "parsed": {
    "relevance": "HIGH",
    "insights": [
      {
        "finding": "Complex, feature-rich code analyzer with multi-stage AI-driven analysis",
        "impact": "MEDIUM",
        "confidence": "HIGH",
        "effort": "LOW",
        "line_number": null,
        "cwe": "N/A",
        "recommendation": "The code demonstrates a robust, modular architecture with clear separation of concerns. Consider adding more comprehensive error handling and logging."
      },
      {
        "finding": "Potential over-reliance on external AI service for code analysis",
        "impact": "MEDIUM",
        "confidence": "MEDIUM",
        "effort": "MEDIUM",
        "line_number": 229,
        "cwe": "CWE-754",
        "recommendation": "Implement fallback mechanisms and local analysis capabilities to reduce dependency on external AI services. Add circuit breaker patterns for API calls."
      },
      {
        "finding": "Large, monolithic script with multiple responsibilities",
        "impact": "LOW",
        "confidence": "HIGH",
        "effort": "HIGH",
        "line_number": null,
        "cwe": "N/A",
        "recommendation": "Consider breaking down the script into smaller, more focused modules. Implement dependency injection and use more abstract interfaces for better testability."
      },
      {
        "finding": "Potential security risk in dynamic prompt generation and AI response parsing",
        "impact": "HIGH",
        "confidence": "MEDIUM",
        "effort": "MEDIUM",
        "line_number": 348,
        "cwe": "CWE-94",
        "recommendation": "Add more robust input sanitization and validation for prompts and AI responses. Implement stricter JSON parsing with schema validation."
      },
      {
        "finding": "Extensive use of environment variables and API key management",
        "impact": "MEDIUM",
        "confidence": "HIGH",
        "effort": "LOW",
        "line_number": 269,
        "cwe": "CWE-522",
        "recommendation": "Enhance API key retrieval with more secure methods like vault integration or secure secret management. Add logging and monitoring for API key access attempts."
      }
    ]
  },
  "timestamp": "2025-10-31T03:57:57.426301+00:00"
}